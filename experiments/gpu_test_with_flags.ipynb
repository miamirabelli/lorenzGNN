{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we test if GPU is working... we will run this notebook on both a server with GPU and on my local machine with only CPU. \n",
    "\n",
    "This notebook is identical to cpu_test and gpu_test\n",
    "\n",
    "On the server, we check nvidia-smi to see if it is actually using GPU. \n",
    "\n",
    "Then, we compare runtimes for this notebook on GPU vs CPU to make sure that GPU isn't inadvertently making things slower (e.g. by repeatedly moving data btwn CPU/GPU, etc). Also we should check how much faster GPU makes things. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipython extension to autoreload imported modules so that any changes will be up to date before running code in this nb\n",
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miamirabelli/Desktop/GNN Research/lorenzGNN/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils.jraph_training import train_and_evaluate_with_data, create_dataset\n",
    "# from utils.jraph_models import MLPGraphNetwork\n",
    "from utils.jraph_data import print_graph_fts\n",
    "from utils.jraph_vis import plot_predictions\n",
    "from utils.hyperparam_tuning import remove_bad_trials, get_best_trial_config, get_best_trial_workdir\n",
    "import ml_collections\n",
    "import optuna \n",
    "from flax import linen as nn\n",
    "from functools import partial\n",
    "from datetime import datetime\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up jax flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['XLA_FLAGS'] = (\n",
    "    '--xla_gpu_enable_triton_softmax_fusion=true '\n",
    "    '--xla_gpu_triton_gemm_any=True '\n",
    "    '--xla_gpu_enable_async_collectives=true '\n",
    "    '--xla_gpu_enable_latency_hiding_scheduler=true '\n",
    "    '--xla_gpu_enable_highest_priority_async_stream=true '\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up functions for optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = \"experiments/tuning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, study_name, datasets):\n",
    "    \"\"\" Defines the objective function to be optimized over, aka the validation loss of a model.\n",
    "    \n",
    "        Args:\n",
    "            trial: object which characterizes the current run \n",
    "            datasets: dictionary of data. we explicitly pass this in so that we don't have to waste runtime regenerating the same dataset over and over. \n",
    "    \"\"\"\n",
    "    start = datetime.now()\n",
    "    # create config \n",
    "    config = ml_collections.ConfigDict()\n",
    "\n",
    "    # Optimizer.\n",
    "    # config.optimizer = \"adam\"\n",
    "    config.optimizer = trial.suggest_categorical(\"optimizer\", [\"adam\", \"sgd\"])\n",
    "    config.learning_rate = trial.suggest_float('learning_rate', 1e-4, 5e-2, \n",
    "                                               log=True)\n",
    "    if config.optimizer == \"sgd\":\n",
    "        config.momentum = trial.suggest_float('momentum', 0, 0.999) # upper bound is inclusive, and we want to exclude a momentum of 1 because that would yield no decay \n",
    "\n",
    "    # Data params that are used in training \n",
    "    config.output_steps = 4\n",
    "\n",
    "    # Training hyperparameters.\n",
    "    config.batch_size = 1 # variable currently not used\n",
    "    config.epochs = 200\n",
    "    config.log_every_epochs = 5\n",
    "    config.eval_every_epochs = 5\n",
    "    config.checkpoint_every_epochs = 10\n",
    "\n",
    "    # GNN hyperparameters.\n",
    "    config.model = 'MLPBlock'\n",
    "    config.dropout_rate = trial.suggest_float('dropout_rate', 0, 0.6)\n",
    "    config.skip_connections = False # This was throwing a broadcast error in add_graphs_tuples_nodes when this was set to True\n",
    "    config.layer_norm = False # TODO perhaps we want to turn on later\n",
    "    config.activation = trial.suggest_categorical(\n",
    "        'activation', [\"relu\", \"elu\", \"leaky_relu\"])\n",
    "    \n",
    "    # choose the hidden layer feature size using powers of 2 \n",
    "    config.edge_features = (\n",
    "        2**trial.suggest_int(\"edge_mlp_1_power\", 1, 3), # range 2 - 8; upper bound is inclusive\n",
    "        2**trial.suggest_int(\"edge_mlp_2_power\", 1, 3), # range 2 - 8\n",
    "    )\n",
    "    config.node_features = (\n",
    "        2**trial.suggest_int(\"node_mlp_1_power\", 1, 8), # range 2 - 512\n",
    "        2**trial.suggest_int(\"node_mlp_2_power\", 1, 8), # range 2 - 512\n",
    "        2) \n",
    "    # note the last feature size will be the number of features that the graph predicts\n",
    "    config.global_features = None\n",
    "\n",
    "    # generate a workdir \n",
    "    # TODO: check if we actually care about referencing this in the future or if we can just create a temp dir \n",
    "    workdir=os.path.join(CHECKPOINT_PATH, study_name, f\"trial_{trial.number}\")\n",
    "\n",
    "    # run training \n",
    "    state, train_metrics, eval_metrics_dict = train_and_evaluate_with_data(config=config, workdir=workdir, datasets=datasets, trial=trial)\n",
    "    \n",
    "    # retrieve and return val loss (MSE)\n",
    "    # print(\"eval_metrics_dict['val'].loss\", eval_metrics_dict['val'].loss)\n",
    "    # print(\"eval_metrics_dict['val'].compute()['loss']\", eval_metrics_dict['val'].compute()['loss'])\n",
    "    # print()\n",
    "    end = datetime.now()\n",
    "\n",
    "    print(f\"objective func took {end - start} to run\")\n",
    "    return eval_metrics_dict['val'].compute()['loss']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_config():\n",
    "    config = ml_collections.ConfigDict()\n",
    "\n",
    "    config.n_samples=10_000\n",
    "    config.input_steps=1\n",
    "    config.output_delay=8 # predict 24 hrs into the future \n",
    "    config.output_steps=4\n",
    "    config.timestep_duration=3 # equivalent to 3 hours\n",
    "    # note a 3 hour timestep resolution would be 5*24/3=40\n",
    "    # if the time_resolution is 120, then a sampling frequency of 3 would achieve a 3 hour timestep \n",
    "    config.sample_buffer = -1 * (config.input_steps + config.output_delay + config.output_steps - 1) # negative buffer so that our sample input are continuous (i.e. the first sample would overlap a bit with consecutive samples) \n",
    "        # number of timesteps strictly between the end \n",
    "        # of one full sample and the start of the next sample\n",
    "    config.time_resolution=120 # the number of \n",
    "                # raw data points generated per time unit, equivalent to the \n",
    "                # number of data points generated per 5 days in the simulation\n",
    "    config.init_buffer_samples=100\n",
    "    config.train_pct=0.7\n",
    "    config.val_pct=0.2\n",
    "    config.test_pct=0.1\n",
    "    config.K=36\n",
    "    config.F=8\n",
    "    config.c=10\n",
    "    config.b=10\n",
    "    config.h=1\n",
    "    config.seed=42\n",
    "    config.normalize=True\n",
    "    config.fully_connected_edges=False\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_study(study_name):\n",
    "    # generate dataset \n",
    "    data_start = datetime.now()\n",
    "    dataset_config = get_data_config()\n",
    "    datasets = create_dataset(dataset_config)\n",
    "    data_end = datetime.now()\n",
    "    print(f\"dataset took {data_end - data_start} time to generate\")\n",
    "    \n",
    "    print_graph_fts(datasets['train']['inputs'][0][0])\n",
    "\n",
    "    # get the objective function that reuses the pre-generated datasets \n",
    "    objective_partial = partial(objective, study_name=study_name, \n",
    "                                datasets=datasets)\n",
    "\n",
    "    # run optimization study\n",
    "    db_path = os.path.join(CHECKPOINT_PATH, study_name, \"optuna_hparam_search.db\")\n",
    "    if not os.path.exists(os.path.join(CHECKPOINT_PATH, study_name)):\n",
    "        os.makedirs(os.path.join(CHECKPOINT_PATH, study_name))\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        study_name=study_name,\n",
    "        storage=f'sqlite:///{db_path}', # generates a new db if it doesn't exist\n",
    "        direction='minimize',\n",
    "        pruner=optuna.pruners.MedianPruner(\n",
    "            n_startup_trials=5, \n",
    "            n_warmup_steps=50,\n",
    "            ), \n",
    "        load_if_exists=True, \n",
    "    )\n",
    "    \n",
    "    return study, objective_partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyperparameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset took 0:00:16.565276 time to generate\n",
      "Number of nodes: 36\n",
      "Number of edges: 180\n",
      "Node features shape: (36, 2)\n",
      "Edge features shape: (180, 1)\n",
      "Global features shape: (1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-12 19:40:35,396] A new study created in RDB with name: hparam_study_gpu\n"
     ]
    }
   ],
   "source": [
    "# get study\n",
    "study_gpu_with_flags, objective_partial = prepare_study(study_name=\"hparam_study_gpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-02-12 19:40:36,152] Trial 0 failed with parameters: {'optimizer': 'sgd', 'learning_rate': 0.00773496415885987, 'momentum': 0.03273441702188007, 'dropout_rate': 0.08561406359508299, 'activation': 'relu', 'edge_mlp_1_power': 3, 'edge_mlp_2_power': 2, 'node_mlp_1_power': 8, 'node_mlp_2_power': 1} because of the following error: AttributeError(KeyError(\"'max_checkpts_to_keep'\")).\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/miamirabelli/Desktop/GNN Research/lorenzGNN/venv/lib/python3.11/site-packages/ml_collections/config_dict/config_dict.py\", line 903, in __getitem__\n",
      "    field = self._fields[key]\n",
      "            ~~~~~~~~~~~~^^^^^\n",
      "KeyError: 'max_checkpts_to_keep'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/miamirabelli/Desktop/GNN Research/lorenzGNN/venv/lib/python3.11/site-packages/ml_collections/config_dict/config_dict.py\", line 827, in __getattr__\n",
      "    return self[attribute]\n",
      "           ~~~~^^^^^^^^^^^\n",
      "  File \"/Users/miamirabelli/Desktop/GNN Research/lorenzGNN/venv/lib/python3.11/site-packages/ml_collections/config_dict/config_dict.py\", line 909, in __getitem__\n",
      "    raise KeyError(self._generate_did_you_mean_message(key, str(e)))\n",
      "KeyError: \"'max_checkpts_to_keep'\"\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/miamirabelli/Desktop/GNN Research/lorenzGNN/venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/ms/_sf7k0cx6tn2h19y34_j6pd40000gn/T/ipykernel_84459/2020598259.py\", line 55, in objective\n",
      "    state, train_metrics, eval_metrics_dict = train_and_evaluate_with_data(config=config, workdir=workdir, datasets=datasets, trial=trial)\n",
      "                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/miamirabelli/Desktop/GNN Research/lorenzGNN/utils/jraph_training.py\", line 531, in train_and_evaluate_with_data\n",
      "    max_to_keep=config.max_checkpts_to_keep)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/miamirabelli/Desktop/GNN Research/lorenzGNN/venv/lib/python3.11/site-packages/ml_collections/config_dict/config_dict.py\", line 829, in __getattr__\n",
      "    raise AttributeError(e)\n",
      "AttributeError: \"'max_checkpts_to_keep'\"\n",
      "[W 2024-02-12 19:40:36,153] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "\"'max_checkpts_to_keep'\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/GNN Research/lorenzGNN/venv/lib/python3.11/site-packages/ml_collections/config_dict/config_dict.py:903\u001b[0m, in \u001b[0;36mConfigDict.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    902\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 903\u001b[0m   field \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fields[key]\n\u001b[1;32m    904\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(field, FieldReference):\n",
      "\u001b[0;31mKeyError\u001b[0m: 'max_checkpts_to_keep'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/GNN Research/lorenzGNN/venv/lib/python3.11/site-packages/ml_collections/config_dict/config_dict.py:827\u001b[0m, in \u001b[0;36mConfigDict.__getattr__\u001b[0;34m(self, attribute)\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 827\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m[attribute]\n\u001b[1;32m    828\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Desktop/GNN Research/lorenzGNN/venv/lib/python3.11/site-packages/ml_collections/config_dict/config_dict.py:909\u001b[0m, in \u001b[0;36mConfigDict.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 909\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate_did_you_mean_message(key, \u001b[39mstr\u001b[39m(e)))\n",
      "\u001b[0;31mKeyError\u001b[0m: \"'max_checkpts_to_keep'\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/miamirabelli/Desktop/GNN Research/lorenzGNN/experiments/gpu_test_with_flags.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/miamirabelli/Desktop/GNN%20Research/lorenzGNN/experiments/gpu_test_with_flags.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m study_gpu_with_flags\u001b[39m.\u001b[39;49moptimize(objective_partial, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/miamirabelli/Desktop/GNN%20Research/lorenzGNN/experiments/gpu_test_with_flags.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                 n_trials\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39mlen\u001b[39;49m(study_gpu_with_flags\u001b[39m.\u001b[39;49mtrials), \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/miamirabelli/Desktop/GNN%20Research/lorenzGNN/experiments/gpu_test_with_flags.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                 n_jobs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/GNN Research/lorenzGNN/venv/lib/python3.11/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     _optimize(\n\u001b[1;32m    452\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    453\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    454\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    455\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    456\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    457\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    458\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    459\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    460\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    461\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/GNN Research/lorenzGNN/venv/lib/python3.11/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/GNN Research/lorenzGNN/venv/lib/python3.11/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/Desktop/GNN Research/lorenzGNN/venv/lib/python3.11/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/Desktop/GNN Research/lorenzGNN/venv/lib/python3.11/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32m/Users/miamirabelli/Desktop/GNN Research/lorenzGNN/experiments/gpu_test_with_flags.ipynb Cell 15\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/miamirabelli/Desktop/GNN%20Research/lorenzGNN/experiments/gpu_test_with_flags.ipynb#X20sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m workdir\u001b[39m=\u001b[39mos\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(CHECKPOINT_PATH, study_name, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrial_\u001b[39m\u001b[39m{\u001b[39;00mtrial\u001b[39m.\u001b[39mnumber\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/miamirabelli/Desktop/GNN%20Research/lorenzGNN/experiments/gpu_test_with_flags.ipynb#X20sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39m# run training \u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/miamirabelli/Desktop/GNN%20Research/lorenzGNN/experiments/gpu_test_with_flags.ipynb#X20sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m state, train_metrics, eval_metrics_dict \u001b[39m=\u001b[39m train_and_evaluate_with_data(config\u001b[39m=\u001b[39;49mconfig, workdir\u001b[39m=\u001b[39;49mworkdir, datasets\u001b[39m=\u001b[39;49mdatasets, trial\u001b[39m=\u001b[39;49mtrial)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/miamirabelli/Desktop/GNN%20Research/lorenzGNN/experiments/gpu_test_with_flags.ipynb#X20sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39m# retrieve and return val loss (MSE)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/miamirabelli/Desktop/GNN%20Research/lorenzGNN/experiments/gpu_test_with_flags.ipynb#X20sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39m# print(\"eval_metrics_dict['val'].loss\", eval_metrics_dict['val'].loss)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/miamirabelli/Desktop/GNN%20Research/lorenzGNN/experiments/gpu_test_with_flags.ipynb#X20sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39m# print(\"eval_metrics_dict['val'].compute()['loss']\", eval_metrics_dict['val'].compute()['loss'])\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/miamirabelli/Desktop/GNN%20Research/lorenzGNN/experiments/gpu_test_with_flags.ipynb#X20sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39m# print()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/miamirabelli/Desktop/GNN%20Research/lorenzGNN/experiments/gpu_test_with_flags.ipynb#X20sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m end \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow()\n",
      "File \u001b[0;32m~/Desktop/GNN Research/lorenzGNN/utils/jraph_training.py:531\u001b[0m, in \u001b[0;36mtrain_and_evaluate_with_data\u001b[0;34m(config, workdir, datasets, trial)\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[39m# Set up checkpointing of the model.\u001b[39;00m\n\u001b[1;32m    527\u001b[0m \u001b[39m# The input pipeline cannot be checkpointed in its current form,\u001b[39;00m\n\u001b[1;32m    528\u001b[0m \u001b[39m# due to the use of stateful operations.\u001b[39;00m\n\u001b[1;32m    529\u001b[0m checkpoint_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(workdir, \u001b[39m'\u001b[39m\u001b[39mcheckpoints\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    530\u001b[0m ckpt \u001b[39m=\u001b[39m checkpoint\u001b[39m.\u001b[39mCheckpoint(checkpoint_dir, \n\u001b[0;32m--> 531\u001b[0m                              max_to_keep\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39;49mmax_checkpts_to_keep)\n\u001b[1;32m    532\u001b[0m state \u001b[39m=\u001b[39m ckpt\u001b[39m.\u001b[39mrestore_or_initialize(state)\n\u001b[1;32m    533\u001b[0m initial_step \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(state\u001b[39m.\u001b[39mstep) \u001b[39m# state.step is 0-indexed \u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/GNN Research/lorenzGNN/venv/lib/python3.11/site-packages/ml_collections/config_dict/config_dict.py:829\u001b[0m, in \u001b[0;36mConfigDict.__getattr__\u001b[0;34m(self, attribute)\u001b[0m\n\u001b[1;32m    827\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[attribute]\n\u001b[1;32m    828\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 829\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(e)\n",
      "\u001b[0;31mAttributeError\u001b[0m: \"'max_checkpts_to_keep'\""
     ]
    }
   ],
   "source": [
    "study_gpu_with_flags.optimize(objective_partial, \n",
    "                n_trials=10-len(study_gpu_with_flags.trials), \n",
    "                n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = create_dataset(get_data_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(\n",
    "    config=get_best_trial_config(study=study_gpu_with_flags),\n",
    "    workdir=get_best_trial_workdir(study=study_gpu_with_flags), # for loading checkpoints \n",
    "    plot_ith_rollout_step=0, # 0 indexed # for this study, we have a 4-step rollout \n",
    "    # dataset,\n",
    "    # preds,\n",
    "    # timestep_duration,\n",
    "    # n_rollout_steps,\n",
    "    #  total_steps,\n",
    "    node=0, # 0-indexed \n",
    "    plot_mode=\"val\", # i.e. \"train\"/\"val\"/\"test\"\n",
    "    datasets=datasets,\n",
    "    plot_all=False, # if false, only plot the first 100 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_vis = remove_bad_trials(study_gpu_with_flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = optuna.visualization.plot_intermediate_values(study_vis)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the estimated accuracy surface over hyperparameters:\n",
    "fig = optuna.visualization.plot_contour(study_vis, params=['learning_rate', 'dropout_rate'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the estimated accuracy surface over hyperparameters:\n",
    "fig = optuna.visualization.plot_contour(study_vis, params=['learning_rate', 'edge_mlp_1_power'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the estimated accuracy surface over hyperparameters:\n",
    "fig = optuna.visualization.plot_contour(study_vis, params=['learning_rate', 'node_mlp_1_power'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the estimated accuracy surface over hyperparameters:\n",
    "fig = optuna.visualization.plot_contour(study_vis, params=['learning_rate', 'optimizer'])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the estimated accuracy surface over hyperparameters:\n",
    "fig = optuna.visualization.plot_contour(study_vis, params=['optimizer', 'activation'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the estimated accuracy surface over hyperparameters:\n",
    "fig = optuna.visualization.plot_contour(study_vis, params=['activation', 'node_mlp_1_power'])\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lorenzvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
