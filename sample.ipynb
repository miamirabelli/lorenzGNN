{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INTRO & GOALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will be generating some data to visualize where the GNN is at right now. I will be paying particular attention on how to generally run the GNN, but I will start looking at the X2 variable. We need to figure out the rollout loss function, but thats a later thing :) one step at a time, girl\n",
    "\n",
    "goals: learn how to use this giant codebase PLEASEEE\n",
    "        see what's goin on here, esp with X2 when compared to X1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTS & SETUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here, we'll import the necessary packages and  make sure auto reload is turned on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipython extension to autoreload imported modules so that any changes will be up to date before running code in this nb\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "from utils.jraph_data import get_lorenz_graph_tuples, print_graph_fts\n",
    "from utils.lorenz import load_lorenz96_2coupled\n",
    "\n",
    "import numpy as np\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONFIGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml_collections\n",
    "\n",
    "config = ml_collections.ConfigDict()\n",
    "\n",
    "# Data params. \n",
    "config.n_samples=20\n",
    "config.input_steps=3\n",
    "config.output_delay=0\n",
    "config.output_steps=2\n",
    "config.timestep_duration=1\n",
    "config.sample_buffer=1\n",
    "config.time_resolution=100\n",
    "config.init_buffer_samples=0\n",
    "config.train_pct=0.7\n",
    "config.val_pct=0.2\n",
    "config.test_pct=0.1\n",
    "config.K=36\n",
    "config.F=8\n",
    "config.c=10\n",
    "config.b=10\n",
    "config.h=1\n",
    "config.seed=42\n",
    "config.normalize=True\n",
    "config.fully_connected_edges=True\n",
    "\n",
    "# Optimizer.\n",
    "config.optimizer = 'adam'\n",
    "config.learning_rate = 1e-3\n",
    "\n",
    "# Training hyperparameters.\n",
    "# config.batch_size = 3\n",
    "config.epochs = 2\n",
    "config.log_every_epochs = 1\n",
    "config.eval_every_epochs = 1\n",
    "config.checkpoint_every_epochs = 1\n",
    "config.max_checkpts_to_keep = None # None means keep all checkpoints\n",
    "\n",
    "# GNN hyperparameters.\n",
    "config.model = 'MLPGraphNetwork'\n",
    "config.n_blocks = 1\n",
    "config.activation = 'relu'\n",
    "config.dropout_rate = 0.1\n",
    "config.skip_connections = False # This was throwing a broadcast error in add_graphs_tuples_nodes when this was set to True\n",
    "config.layer_norm = False # TODO perhaps we want to turn on later\n",
    "config.edge_features = (4, 8) # the last feature size will be the number of features that the graph predicts\n",
    "config.node_features = (32, 2)\n",
    "config.global_features = None\n",
    "config.share_params = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LORENZ DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.lorenz import run_download_lorenz96_2coupled, load_lorenz96_2coupled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll run the model and save it to a .npz file, called sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_download_lorenz96_2coupled(\n",
    "        fname=\"data/sample\", \n",
    "        K=config.K,\n",
    "        F=config.F,\n",
    "        c=config.c,\n",
    "        b=config.b,\n",
    "        h=config.h,\n",
    "        n_steps=100,\n",
    "        resolution=config.time_resolution,\n",
    "        seed=config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load and visualize the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 72)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 8.        ,  8.        ,  8.        , ...,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [ 7.9902934 ,  7.99291748,  7.990142  , ...,  0.9810261 ,\n",
       "         0.98093732,  0.98058919],\n",
       "       [ 7.98172884,  7.99153972,  7.98050267, ...,  0.9642227 ,\n",
       "         0.96387367,  0.96249242],\n",
       "       ...,\n",
       "       [ 4.07438531, -6.49933927, -4.01271857, ..., -0.25178268,\n",
       "         0.09335156,  0.67455085],\n",
       "       [ 3.19825674, -6.76234763, -3.51776105, ..., -0.28000194,\n",
       "         0.16628708,  0.67592144],\n",
       "       [ 2.3056217 , -6.90947962, -3.06928609, ..., -0.32770479,\n",
       "         0.20752579,  0.67467634]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t, X = load_lorenz96_2coupled(fname=\"data/sample.npz\")\n",
    "print(X.shape)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GraphsTuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use Lorenz96 data, we'll use the GraphsTuples object from jraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.jraph_data import get_lorenz_graph_tuples, print_graph_fts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate desired dataset with train/val split and subsampled windows\n",
    "graph_tuple_dict = get_lorenz_graph_tuples(\n",
    "    n_samples=config.n_samples,\n",
    "    input_steps=config.input_steps,\n",
    "    output_delay=config.output_delay,\n",
    "    output_steps=config.output_steps,\n",
    "    timestep_duration=config.timestep_duration,\n",
    "    sample_buffer=config.sample_buffer,\n",
    "    time_resolution=config.time_resolution,\n",
    "    init_buffer_samples=config.init_buffer_samples,\n",
    "    train_pct=config.train_pct,\n",
    "    val_pct=config.val_pct,\n",
    "    test_pct=config.test_pct,\n",
    "    K=config.K,\n",
    "    F=config.F,\n",
    "    c=config.c,\n",
    "    b=config.b,\n",
    "    h=config.h,\n",
    "    seed=config.seed,\n",
    "    normalize=config.normalize,\n",
    "    fully_connected_edges=config.fully_connected_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at what we generated! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph_tuple_dict type: <class 'dict'>\n",
      "graph_tuple_dict keys: dict_keys(['train', 'val', 'test'])\n",
      "graph_tuple_dict value type: <class 'dict'>\n",
      "train dataset keys: dict_keys(['inputs', 'targets'])\n",
      "train dataset value type: <class 'list'>\n",
      "size of train inputs: 14\n",
      "size of train targets: 14\n",
      "size of val inputs: 4\n",
      "size of val targets: 4\n",
      "size of test inputs: 2\n",
      "size of test targets: 2\n",
      "train inputs window type: <class 'list'>\n",
      "train input window size (i.e. input steps per window): 3\n",
      "element type in window: <class 'jraph._src.graph.GraphsTuple'>\n"
     ]
    }
   ],
   "source": [
    "train_dataset = graph_tuple_dict['train']\n",
    "val_dataset = graph_tuple_dict['val']\n",
    "test_dataset = graph_tuple_dict['test']\n",
    "\n",
    "train_inputs = train_dataset['inputs']\n",
    "train_targets = train_dataset['targets']\n",
    "val_inputs = val_dataset['inputs']\n",
    "val_targets = val_dataset['targets']\n",
    "test_inputs = test_dataset['inputs']\n",
    "test_targets = test_dataset['targets']\n",
    "\n",
    "sample_input_window = train_inputs[0]\n",
    "sample_target_window = train_targets[0]\n",
    "sample_graph = sample_input_window[0]\n",
    "\n",
    "print(\"graph_tuple_dict type:\", type(graph_tuple_dict))\n",
    "print(\"graph_tuple_dict keys:\", graph_tuple_dict.keys())\n",
    "print(\"graph_tuple_dict value type:\", type(train_dataset))\n",
    "print(\"train dataset keys:\", train_dataset.keys())\n",
    "print(\"train dataset value type:\", type(train_inputs))\n",
    "\n",
    "print(\"size of train inputs:\", len(train_inputs))\n",
    "print(\"size of train targets:\", len(train_targets))\n",
    "print(\"size of val inputs:\", len(val_inputs))\n",
    "print(\"size of val targets:\", len(val_targets))\n",
    "print(\"size of test inputs:\", len(test_inputs))\n",
    "print(\"size of test targets:\", len(test_targets))\n",
    "\n",
    "print(\"train inputs window type:\", type(sample_input_window))\n",
    "print(\"train input window size (i.e. input steps per window):\", len(sample_input_window))\n",
    "print(\"element type in window:\", type(sample_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphsTuple(nodes=array([[0.25872645, 1.344831  ],\n",
      "       [0.25872645, 1.344831  ],\n",
      "       [0.25872645, 1.344831  ],\n",
      "       [0.25872645, 1.344831  ],\n",
      "       [0.25872645, 1.344831  ],\n",
      "       [0.25872645, 1.344831  ],\n",
      "       [0.25872645, 1.344831  ],\n",
      "       [0.25872645, 1.344831  ],\n",
      "       [0.25872645, 1.344831  ],\n",
      "       [0.25872645, 1.344831  ],\n",
      "       [0.25872645, 1.344831  ],\n",
      "       [0.25872645, 1.344831  ],\n",
      "       [0.25872645, 1.344831  ],\n",
      "       [0.25872645, 1.344831  ],\n",
      "       [0.25872645, 1.344831  ],\n",
      "       [0.25872645, 1.344831  ],\n",
      "       [0.25881994, 1.344831  ],\n",
      "       [0.25872645, 1.344831  ],\n",
      "       [0.25872645, 1.344831  ],\n",
      "       [0.25872645, 1.344831  ],\n",
      "       [0.25872645, 1.344831  ],\n",
      "       [0.25872645, 1.344831  ],\n",
      "       [0.25872645, 1.344831  ],\n",
      "       [0.25872645, 1.344831  ],\n",
      "       [0.25872645, 1.344831  ],\n",
      "       [0.25872645, 1.344831  ],\n",
      "       [0.25872645, 1.344831  ],\n",
      "       [0.25872645, 1.344831  ],\n",
      "       [0.25872645, 1.344831  ],\n",
      "       [0.25872645, 1.344831  ],\n",
      "       [0.25872645, 1.344831  ],\n",
      "       [0.25872645, 1.344831  ],\n",
      "       [0.25872645, 1.344831  ],\n",
      "       [0.25872645, 1.344831  ],\n",
      "       [0.25872645, 1.344831  ],\n",
      "       [0.25872645, 1.344831  ]], dtype=float32), edges=Array([[ 0.],\n",
      "       [-1.],\n",
      "       [-2.],\n",
      "       ...,\n",
      "       [ 2.],\n",
      "       [ 1.],\n",
      "       [ 0.]], dtype=float32), receivers=Array([ 0,  1,  2, ..., 33, 34, 35], dtype=int32), senders=Array([ 0,  0,  0, ..., 35, 35, 35], dtype=int32), globals=Array([[1.]], dtype=float32), n_node=Array([36], dtype=int32), n_edge=Array([1296], dtype=int32))\n"
     ]
    }
   ],
   "source": [
    "print(sample_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 36\n",
      "Number of edges: 1296\n",
      "Node features shape: (36, 2)\n",
      "Edge features shape: (1296, 1)\n",
      "Global features shape: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "print_graph_fts(sample_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.25872645, 1.344831  ],\n",
       "       [0.25872645, 1.344831  ],\n",
       "       [0.25872645, 1.344831  ],\n",
       "       [0.25872645, 1.344831  ],\n",
       "       [0.25872645, 1.344831  ],\n",
       "       [0.25872645, 1.344831  ],\n",
       "       [0.25872645, 1.344831  ],\n",
       "       [0.25872645, 1.344831  ],\n",
       "       [0.25872645, 1.344831  ],\n",
       "       [0.25872645, 1.344831  ],\n",
       "       [0.25872645, 1.344831  ],\n",
       "       [0.25872645, 1.344831  ],\n",
       "       [0.25872645, 1.344831  ],\n",
       "       [0.25872645, 1.344831  ],\n",
       "       [0.25872645, 1.344831  ],\n",
       "       [0.25872645, 1.344831  ],\n",
       "       [0.25881994, 1.344831  ],\n",
       "       [0.25872645, 1.344831  ],\n",
       "       [0.25872645, 1.344831  ],\n",
       "       [0.25872645, 1.344831  ],\n",
       "       [0.25872645, 1.344831  ],\n",
       "       [0.25872645, 1.344831  ],\n",
       "       [0.25872645, 1.344831  ],\n",
       "       [0.25872645, 1.344831  ],\n",
       "       [0.25872645, 1.344831  ],\n",
       "       [0.25872645, 1.344831  ],\n",
       "       [0.25872645, 1.344831  ],\n",
       "       [0.25872645, 1.344831  ],\n",
       "       [0.25872645, 1.344831  ],\n",
       "       [0.25872645, 1.344831  ],\n",
       "       [0.25872645, 1.344831  ],\n",
       "       [0.25872645, 1.344831  ],\n",
       "       [0.25872645, 1.344831  ],\n",
       "       [0.25872645, 1.344831  ],\n",
       "       [0.25872645, 1.344831  ],\n",
       "       [0.25872645, 1.344831  ]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# node features (i.e. 36 nodes x 2 layers)\n",
    "print(graph_tuple_dict['train']['inputs'][0][0].nodes.shape)\n",
    "graph_tuple_dict['train']['inputs'][0][0].nodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1296, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array([[ 0.],\n",
       "       [-1.],\n",
       "       [-2.],\n",
       "       ...,\n",
       "       [ 2.],\n",
       "       [ 1.],\n",
       "       [ 0.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# edge features \n",
    "print(graph_tuple_dict['train']['inputs'][0][0].edges.shape)\n",
    "graph_tuple_dict['train']['inputs'][0][0].edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.jraph_models import MLPGraphNetwork\n",
    "import flax.linen as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPGraphNetwork(\n",
       "    # attributes\n",
       "    n_blocks = 1\n",
       "    share_params = False\n",
       "    dropout_rate = 0.1\n",
       "    skip_connections = False\n",
       "    layer_norm = False\n",
       "    deterministic = True\n",
       "    activation = relu\n",
       "    edge_features = (4, 8)\n",
       "    node_features = (32, 2)\n",
       "    global_features = None\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_funcs = {\n",
    "    \"relu\": nn.relu,\n",
    "    \"elu\": nn.elu,\n",
    "    \"leaky_relu\": nn.leaky_relu,\n",
    "}\n",
    "activation = activation_funcs[config.activation]\n",
    "\n",
    "model = MLPGraphNetwork(            \n",
    "    n_blocks=config.n_blocks,\n",
    "    share_params=config.share_params,\n",
    "    dropout_rate=config.dropout_rate,\n",
    "    skip_connections=config.skip_connections,\n",
    "    layer_norm=config.layer_norm,\n",
    "    deterministic=True,\n",
    "    activation=activation,\n",
    "    edge_features=config.edge_features,\n",
    "    node_features=config.node_features,\n",
    "    global_features=config.global_features,\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Jax and Flax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from flax.training import train_state\n",
    "import optax # library with optimizer classes used with jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and initialize the parameters.\n",
    "rng = jax.random.key(0)\n",
    "rng, init_rng = jax.random.split(rng)\n",
    "params = jax.jit(model.init)(init_rng, sample_input_window)\n",
    "\n",
    "# Create an optimizer (you can create different types of optimizers, e.g. adam, SGD, etc.)\n",
    "tx = optax.adam(learning_rate=config.learning_rate)\n",
    "\n",
    "# Create the training state.\n",
    "state = train_state.TrainState.create(\n",
    "    apply_fn=model.apply, params=params, tx=tx\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's train her raaahhhhh\n",
    "training consists of:\n",
    "  1. computing rollout and loss for forward pass\n",
    "  2. updating model parameters based on gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miamirabelli/Desktop/GNN Research/lorenzGNN/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils.jraph_training import create_model, train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and initialize the network.\n",
    "rng = jax.random.key(0)\n",
    "rng, init_rng = jax.random.split(rng)\n",
    "init_net = create_model(config, deterministic=True)\n",
    "params = jax.jit(init_net.init)(init_rng, sample_input_window)\n",
    "\n",
    "# Create the optimizer.\n",
    "tx = optax.adam(learning_rate=config.learning_rate)\n",
    "\n",
    "# Create the training state.\n",
    "net = create_model(config, deterministic=False)\n",
    "state = train_state.TrainState.create(\n",
    "    apply_fn=net.apply, params=params, tx=tx\n",
    ")\n",
    "\n",
    "rng, dropout_rng = jax.random.split(rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, metrics_update, pred_nodes = train_step(\n",
    "    state=state,\n",
    "    n_rollout_steps=config.output_steps,\n",
    "    input_window_graphs=sample_input_window,\n",
    "    target_window_graphs=sample_target_window,\n",
    "    rngs={'dropout': dropout_rng})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Array([[ -98.677925 ,  -39.921608 ],\n",
       "        [-120.49141  ,  -50.34245  ],\n",
       "        [-104.10326  ,  -36.979153 ],\n",
       "        [ -91.72362  ,  -45.435158 ],\n",
       "        [-102.39267  ,  -23.706974 ],\n",
       "        [-105.23367  ,  -38.129932 ],\n",
       "        [-107.99461  ,  -34.88067  ],\n",
       "        [ -75.59826  ,   -2.6439323],\n",
       "        [-107.7919   ,  -55.576904 ],\n",
       "        [   0.       ,  -81.21098  ],\n",
       "        [-120.722084 ,  -47.333466 ],\n",
       "        [   0.       ,  -99.847534 ],\n",
       "        [ -61.948605 ,  -91.852066 ],\n",
       "        [   0.       ,  -19.734015 ],\n",
       "        [-114.468636 ,  -39.501007 ],\n",
       "        [-108.012985 ,   -7.4714293],\n",
       "        [ -91.07166  ,    0.       ],\n",
       "        [ -57.29462  ,    0.       ],\n",
       "        [   0.       ,  -39.664696 ],\n",
       "        [ -82.92592  ,  -11.086294 ],\n",
       "        [-102.702866 ,  -42.68212  ],\n",
       "        [ -93.784676 ,  -39.14112  ],\n",
       "        [-107.27273  ,  -63.723972 ],\n",
       "        [ -72.325096 ,  -66.53959  ],\n",
       "        [ -68.340866 ,  -87.95836  ],\n",
       "        [ -90.03129  ,  -48.926582 ],\n",
       "        [ -91.88275  ,   -0.9935209],\n",
       "        [-106.62933  ,   -7.7114897],\n",
       "        [ -62.931767 ,    2.6885633],\n",
       "        [-104.1441   ,  -30.487354 ],\n",
       "        [   0.       ,  -49.252693 ],\n",
       "        [   0.       ,    0.       ],\n",
       "        [-110.31584  ,  -34.4162   ],\n",
       "        [-108.63603  ,  -60.364872 ],\n",
       "        [-107.26558  ,  -34.46278  ],\n",
       "        [-105.96918  ,  -43.04252  ]], dtype=float32),\n",
       " Array([[ -98.7262   ,  -39.9499   ],\n",
       "        [-120.56743  ,  -50.402737 ],\n",
       "        [-104.130005 ,  -37.027817 ],\n",
       "        [ -91.75908  ,  -45.58351  ],\n",
       "        [-102.44264  ,  -23.787142 ],\n",
       "        [-105.27907  ,  -38.14805  ],\n",
       "        [-108.02981  ,  -34.922626 ],\n",
       "        [ -75.66555  ,   -2.6468148],\n",
       "        [-107.870674 ,  -55.57448  ],\n",
       "        [   0.       ,  -81.30731  ],\n",
       "        [-120.79009  ,  -47.406124 ],\n",
       "        [   0.       ,  -99.97928  ],\n",
       "        [ -61.978203 ,  -91.92596  ],\n",
       "        [   0.       ,  -19.811262 ],\n",
       "        [-114.52519  ,  -39.540695 ],\n",
       "        [-108.023895 ,   -7.419    ],\n",
       "        [ -91.14054  ,    0.       ],\n",
       "        [ -57.28967  ,    0.       ],\n",
       "        [   0.       ,  -39.669067 ],\n",
       "        [ -82.92543  ,  -11.086861 ],\n",
       "        [-102.75735  ,  -42.715668 ],\n",
       "        [ -93.85601  ,  -39.12049  ],\n",
       "        [-107.35241  ,  -63.757923 ],\n",
       "        [ -72.35126  ,  -66.661476 ],\n",
       "        [ -68.36243  ,  -88.126945 ],\n",
       "        [ -90.07001  ,  -48.960915 ],\n",
       "        [ -91.902756 ,   -1.018387 ],\n",
       "        [-106.68354  ,   -7.730284 ],\n",
       "        [ -62.993454 ,    2.7190173],\n",
       "        [-104.17475  ,  -30.479767 ],\n",
       "        [   0.       ,  -49.245052 ],\n",
       "        [   0.       ,    0.       ],\n",
       "        [-110.32677  ,  -34.450794 ],\n",
       "        [-108.71026  ,  -60.40383  ],\n",
       "        [-107.334496 ,  -34.52833  ],\n",
       "        [-105.91433  ,  -43.127934 ]], dtype=float32)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here's the loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainMetrics(_reduction_counter=_ReductionCounter(value=Array(1, dtype=int32, weak_type=True)), loss=Metric.from_output.<locals>.FromOutput(total=Array(5125.2095, dtype=float32), count=Array(1., dtype=float32)))\n",
      "access loss like this: 5125.2095\n"
     ]
    }
   ],
   "source": [
    "print(metrics_update)\n",
    "print('access loss like this:', metrics_update.loss.total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VALIDATION & TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validation happens every epoch, or every X epochs (if seeking to reduce runtime).\n",
    "\n",
    "remember that testing should NOT happen until end of model development. validation dataset helps model development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.jraph_training import evaluate_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, during evaluation, we want to turn OFF the `dropout` and `deterministic` params in the model instantiation, so we make a new model; in our state we want to copy the params from the training state, keep the correct `apply` function from the new evaluatio model, and don't care about optimizers because we're just doing evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the evaluation state, corresponding to a deterministic model.\n",
    "eval_net = create_model(config, deterministic=True) # Note that dropout is deactivated if deterministic is True. \n",
    "eval_state = state.replace(apply_fn=eval_net.apply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metrics, pred_nodes = evaluate_step(\n",
    "    state=eval_state,\n",
    "    n_rollout_steps=config.output_steps,\n",
    "    input_window_graphs=sample_input_window,\n",
    "    target_window_graphs=sample_target_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Array([[-83.19219 , -30.645147],\n",
       "        [-83.19219 , -30.645147],\n",
       "        [-83.19219 , -30.645155],\n",
       "        [-83.19219 , -30.645142],\n",
       "        [-83.19219 , -30.64515 ],\n",
       "        [-83.19219 , -30.645157],\n",
       "        [-83.19219 , -30.645155],\n",
       "        [-83.19219 , -30.64516 ],\n",
       "        [-83.192184, -30.645163],\n",
       "        [-83.19219 , -30.645164],\n",
       "        [-83.19219 , -30.645159],\n",
       "        [-83.19219 , -30.64516 ],\n",
       "        [-83.19219 , -30.645168],\n",
       "        [-83.19219 , -30.645157],\n",
       "        [-83.1922  , -30.64517 ],\n",
       "        [-83.1922  , -30.64519 ],\n",
       "        [-83.1923  , -30.64483 ],\n",
       "        [-83.19217 , -30.645159],\n",
       "        [-83.19216 , -30.645151],\n",
       "        [-83.19215 , -30.645138],\n",
       "        [-83.19215 , -30.645132],\n",
       "        [-83.19215 , -30.645138],\n",
       "        [-83.19215 , -30.645136],\n",
       "        [-83.19215 , -30.645136],\n",
       "        [-83.19215 , -30.645138],\n",
       "        [-83.19215 , -30.645123],\n",
       "        [-83.19214 , -30.645124],\n",
       "        [-83.19215 , -30.645138],\n",
       "        [-83.19215 , -30.645136],\n",
       "        [-83.19215 , -30.645128],\n",
       "        [-83.19215 , -30.645124],\n",
       "        [-83.19215 , -30.645128],\n",
       "        [-83.192154, -30.645136],\n",
       "        [-83.192154, -30.645134],\n",
       "        [-83.19219 , -30.645151],\n",
       "        [-83.19219 , -30.645142]], dtype=float32),\n",
       " Array([[-83.22858 , -30.676626],\n",
       "        [-83.23091 , -30.672771],\n",
       "        [-83.23177 , -30.67916 ],\n",
       "        [-83.23167 , -30.679142],\n",
       "        [-83.231606, -30.678928],\n",
       "        [-83.231606, -30.67891 ],\n",
       "        [-83.23162 , -30.678919],\n",
       "        [-83.23161 , -30.678917],\n",
       "        [-83.23163 , -30.678919],\n",
       "        [-83.231606, -30.67892 ],\n",
       "        [-83.23163 , -30.678919],\n",
       "        [-83.23161 , -30.678915],\n",
       "        [-83.23161 , -30.67891 ],\n",
       "        [-83.23163 , -30.678938],\n",
       "        [-83.23163 , -30.678951],\n",
       "        [-83.2316  , -30.678839],\n",
       "        [-83.23124 , -30.678196],\n",
       "        [-83.22104 , -30.669584],\n",
       "        [-83.22015 , -30.67171 ],\n",
       "        [-83.2206  , -30.671993],\n",
       "        [-83.220634, -30.671898],\n",
       "        [-83.22062 , -30.671888],\n",
       "        [-83.220634, -30.671892],\n",
       "        [-83.22062 , -30.67189 ],\n",
       "        [-83.22063 , -30.671885],\n",
       "        [-83.220634, -30.67188 ],\n",
       "        [-83.22062 , -30.671883],\n",
       "        [-83.22063 , -30.671904],\n",
       "        [-83.220634, -30.671892],\n",
       "        [-83.22061 , -30.671774],\n",
       "        [-83.22063 , -30.671843],\n",
       "        [-83.22066 , -30.672361],\n",
       "        [-83.22065 , -30.671919],\n",
       "        [-83.220856, -30.667856],\n",
       "        [-83.21882 , -30.670702],\n",
       "        [-83.1932  , -30.763962]], dtype=float32)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(3990.5767, dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_metrics.loss.total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the values are different from above & the loss went down!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FULL PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.jraph_training import train_and_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Obtaining datasets.\n",
      "INFO:absl:Hyperparameters: {'F': 8, 'K': 36, 'activation': 'relu', 'b': 10, 'c': 10, 'checkpoint_every_epochs': 1, 'dropout_rate': 0.1, 'edge_features': (4, 8), 'epochs': 2, 'eval_every_epochs': 1, 'fully_connected_edges': True, 'global_features': None, 'h': 1, 'init_buffer_samples': 0, 'input_steps': 3, 'layer_norm': False, 'learning_rate': 0.001, 'log_every_epochs': 1, 'max_checkpts_to_keep': None, 'model': 'MLPGraphNetwork', 'n_blocks': 1, 'n_samples': 20, 'node_features': (32, 2), 'normalize': True, 'optimizer': 'adam', 'output_delay': 0, 'output_steps': 2, 'sample_buffer': 1, 'seed': 42, 'share_params': False, 'skip_connections': False, 'test_pct': 0.1, 'time_resolution': 100, 'timestep_duration': 1, 'train_pct': 0.7, 'val_pct': 0.2}\n",
      "INFO:absl:Initializing network.\n",
      "INFO:absl:\n",
      "+----------------------------------------+----------+------+----------+-------+\n",
      "| Name                                   | Shape    | Size | Mean     | Std   |\n",
      "+----------------------------------------+----------+------+----------+-------+\n",
      "| params/MLPBlock_0/MLP_0/Dense_0/bias   | (4,)     | 4    | 0.0      | 0.0   |\n",
      "| params/MLPBlock_0/MLP_0/Dense_0/kernel | (6, 4)   | 24   | -0.0819  | 0.36  |\n",
      "| params/MLPBlock_0/MLP_0/Dense_1/bias   | (8,)     | 8    | 0.0      | 0.0   |\n",
      "| params/MLPBlock_0/MLP_0/Dense_1/kernel | (4, 8)   | 32   | -0.0639  | 0.439 |\n",
      "| params/MLPBlock_0/MLP_1/Dense_0/bias   | (32,)    | 32   | 0.0      | 0.0   |\n",
      "| params/MLPBlock_0/MLP_1/Dense_0/kernel | (19, 32) | 608  | -0.00843 | 0.219 |\n",
      "| params/MLPBlock_0/MLP_1/Dense_1/bias   | (2,)     | 2    | 0.0      | 0.0   |\n",
      "| params/MLPBlock_0/MLP_1/Dense_1/kernel | (32, 2)  | 64   | -0.00627 | 0.195 |\n",
      "+----------------------------------------+----------+------+----------+-------+\n",
      "Total: 774\n",
      "INFO:absl:Checkpoint.restore_or_initialize() ...\n",
      "INFO:absl:No checkpoint specified. Restore the latest checkpoint.\n",
      "INFO:absl:Restoring checkpoint: tests/outputs/sample2/checkpoints/ckpt-3\n",
      "INFO:absl:Restored save_counter=3 restored_checkpoint=tests/outputs/sample2/checkpoints/ckpt-3\n",
      "INFO:absl:Checkpoint.restore_or_initialize() finished after 0.00s.\n",
      "INFO:absl:Starting training.\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'eval_metrics_dict' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/miamirabelli/Desktop/GNN Research/lorenzGNN/sample.ipynb Cell 50\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/miamirabelli/Desktop/GNN%20Research/lorenzGNN/sample.ipynb#Y100sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m workdir\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtests/outputs/sample2\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/miamirabelli/Desktop/GNN%20Research/lorenzGNN/sample.ipynb#Y100sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m trained_state, train_metrics, eval_metrics_dict \u001b[39m=\u001b[39m train_and_evaluate(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/miamirabelli/Desktop/GNN%20Research/lorenzGNN/sample.ipynb#Y100sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     config\u001b[39m=\u001b[39;49mconfig, workdir\u001b[39m=\u001b[39;49mworkdir)\n",
      "File \u001b[0;32m~/Desktop/GNN Research/lorenzGNN/utils/jraph_training.py:474\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(config, workdir, trial)\u001b[0m\n\u001b[1;32m    471\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mObtaining datasets.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    472\u001b[0m datasets \u001b[39m=\u001b[39m create_dataset(config)\n\u001b[0;32m--> 474\u001b[0m \u001b[39mreturn\u001b[39;00m train_and_evaluate_with_data(\n\u001b[1;32m    475\u001b[0m     config\u001b[39m=\u001b[39;49mconfig, workdir\u001b[39m=\u001b[39;49mworkdir, datasets\u001b[39m=\u001b[39;49mdatasets, trial\u001b[39m=\u001b[39;49mtrial)\n",
      "File \u001b[0;32m~/Desktop/GNN Research/lorenzGNN/utils/jraph_training.py:638\u001b[0m, in \u001b[0;36mtrain_and_evaluate_with_data\u001b[0;34m(config, workdir, datasets, trial)\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[39mwith\u001b[39;00m report_progress\u001b[39m.\u001b[39mtimed(\u001b[39m'\u001b[39m\u001b[39mcheckpoint\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    637\u001b[0m             ckpt\u001b[39m.\u001b[39msave(state)\n\u001b[0;32m--> 638\u001b[0m \u001b[39mreturn\u001b[39;00m state, train_metrics, eval_metrics_dict\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'eval_metrics_dict' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "workdir=\"tests/outputs/sample2\"\n",
    "\n",
    "trained_state, train_metrics, eval_metrics_dict = train_and_evaluate(\n",
    "    config=config, workdir=workdir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HYPERPARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna \n",
    "from utils.jraph_training import train_and_evaluate_with_data, create_dataset\n",
    "import os \n",
    "from functools import partial\n",
    "\n",
    "CHECKPOINT_PATH = 'experiments/tuning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, study_name, datasets):\n",
    "    \"\"\" Defines the objective function to be optimized over, aka the validation loss of a model.\n",
    "    \n",
    "        Args:\n",
    "            trial: object which characterizes the current run \n",
    "            datasets: dictionary of data. we explicitly pass this in so that we don't have to waste runtime regenerating the same dataset over and over. \n",
    "    \"\"\"\n",
    "    # create config \n",
    "    config = ml_collections.ConfigDict()\n",
    "\n",
    "    # Data params. \n",
    "    config.n_samples=20\n",
    "    config.input_steps=3\n",
    "    config.output_delay=0\n",
    "    config.output_steps=2\n",
    "    config.timestep_duration=1\n",
    "    config.sample_buffer=1\n",
    "    config.time_resolution=100\n",
    "    config.init_buffer_samples=0\n",
    "    config.train_pct=0.7\n",
    "    config.val_pct=0.2\n",
    "    config.test_pct=0.1\n",
    "    config.K=36\n",
    "    config.F=8\n",
    "    config.c=10\n",
    "    config.b=10\n",
    "    config.h=1\n",
    "    config.seed=42\n",
    "    config.normalize=True\n",
    "    config.fully_connected_edges=True\n",
    "\n",
    "    config.max_checkpts_to_keep = 2\n",
    "\n",
    "    # Optimizer.\n",
    "    # config.optimizer = \"adam\"\n",
    "    config.optimizer = trial.suggest_categorical(\"optimizer\", [\"adam\", \"sgd\"])\n",
    "    config.learning_rate = trial.suggest_float('learning_rate', 3e-4, 3e-3, \n",
    "                                               log=True)\n",
    "    if config.optimizer == \"sgd\":\n",
    "        config.momentum = trial.suggest_float('momentum', 0, 0.999) # upper bound is inclusive, and we want to exclude a momentum of 1 because that would yield no decay \n",
    "\n",
    "    # Training hyperparameters.\n",
    "    config.batch_size = 1 # variable currently not used\n",
    "    config.epochs = 4\n",
    "    config.log_every_epochs = 1\n",
    "    config.eval_every_epochs = 1\n",
    "    config.checkpoint_every_epochs = 1\n",
    "\n",
    "    # GNN hyperparameters.\n",
    "    config.model = 'MLPGraphNetwork'\n",
    "    config.n_blocks = trial.suggest_int('n_blocks', 1, 3)\n",
    "    config.share_params = False\n",
    "    config.dropout_rate = trial.suggest_float('dropout_rate', 0, 0.2)\n",
    "    config.skip_connections = False # This was throwing a broadcast error in add_graphs_tuples_nodes when this was set to True\n",
    "    config.layer_norm = False # TODO perhaps we want to turn on later\n",
    "    config.activation = trial.suggest_categorical(\n",
    "        'activation', [\"relu\", \"elu\", \"leaky_relu\"])\n",
    "    # config.activation = \"leaky_relu\"\n",
    "    \n",
    "    config.pred_x1 = True\n",
    "    config.pred_x2 = True\n",
    "\n",
    "    if config.pred_x1 and config.pred_x2:\n",
    "        output_layer = 2\n",
    "    else:\n",
    "        output_layer = 1\n",
    "\n",
    "    # choose the hidden layer feature size using powers of 2 \n",
    "    config.edge_features = (\n",
    "        2**trial.suggest_int(\"edge_mlp_1_power\", 1, 3), # range 2 - 8; upper bound is inclusive\n",
    "        2**trial.suggest_int(\"edge_mlp_2_power\", 1, 3), # range 2 - 8\n",
    "    )\n",
    "    config.node_features = (\n",
    "        2**trial.suggest_int(\"node_mlp_1_power\", 1, 6), \n",
    "        # 2**trial.suggest_int(\"node_mlp_2_power\", 1, 6), \n",
    "        output_layer) \n",
    "    # note the last feature size will be the number of features that the graph predicts\n",
    "    config.global_features = None\n",
    "\n",
    "    # generate a workdir \n",
    "    # TODO: check if we actually care about referencing this in the future or if we can just create a temp dir \n",
    "    workdir=os.path.join(CHECKPOINT_PATH, study_name, f\"trial_{trial.number}\")\n",
    "\n",
    "    # run training \n",
    "    state, train_metrics, eval_metrics_dict = train_and_evaluate_with_data(config=config, workdir=workdir, datasets=datasets, trial=trial)\n",
    "    \n",
    "    # retrieve and return val loss (MSE)\n",
    "    return eval_metrics_dict['val'].compute()['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dataset \n",
    "datasets = create_dataset(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_study(study_name):\n",
    "    # get the objective function that reuses the pre-generated datasets \n",
    "    objective_partial = partial(objective, study_name=study_name, \n",
    "                                datasets=datasets)\n",
    "\n",
    "    # run optimization study\n",
    "    db_path = os.path.join(CHECKPOINT_PATH, study_name, \"optuna_hparam_search.db\")\n",
    "    if not os.path.exists(os.path.join(CHECKPOINT_PATH, study_name)):\n",
    "        os.makedirs(os.path.join(CHECKPOINT_PATH, study_name))\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        study_name=study_name,\n",
    "        storage=f'sqlite:///{db_path}', # generates a new db if it doesn't exist\n",
    "        direction='minimize',\n",
    "        pruner=optuna.pruners.MedianPruner(\n",
    "            n_startup_trials=5, \n",
    "            n_warmup_steps=50,\n",
    "            ), \n",
    "        load_if_exists=True, \n",
    "    )\n",
    "    \n",
    "    return study, objective_partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-12 19:45:30,380] A new study created in RDB with name: sample\n"
     ]
    }
   ],
   "source": [
    "# create the study\n",
    "study, objective_partial = prepare_study(study_name=\"sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn off logging because it'll get annoying \n",
    "logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'study' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/miamirabelli/Desktop/GNN Research/lorenzGNN/sample.ipynb Cell 58\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/miamirabelli/Desktop/GNN%20Research/lorenzGNN/sample.ipynb#Y111sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# run the optimization \u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/miamirabelli/Desktop/GNN%20Research/lorenzGNN/sample.ipynb#Y111sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m study\u001b[39m.\u001b[39moptimize(objective_partial, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/miamirabelli/Desktop/GNN%20Research/lorenzGNN/sample.ipynb#Y111sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                 n_trials\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m\u001b[39m-\u001b[39m\u001b[39mlen\u001b[39m(study\u001b[39m.\u001b[39mtrials), \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/miamirabelli/Desktop/GNN%20Research/lorenzGNN/sample.ipynb#Y111sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                 n_jobs\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'study' is not defined"
     ]
    }
   ],
   "source": [
    "# run the optimization \n",
    "study.optimize(objective_partial, \n",
    "                n_trials=5-len(study.trials), \n",
    "                n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FrozenTrial(number=0, state=2, values=None, datetime_start=datetime.datetime(2024, 2, 12, 19, 45, 51, 713962), datetime_complete=datetime.datetime(2024, 2, 12, 19, 45, 53, 567799), params={'optimizer': 'sgd', 'learning_rate': 0.0022587733026897374, 'momentum': 0.6845521345216822, 'n_blocks': 2, 'dropout_rate': 0.029194087165737792, 'activation': 'relu', 'edge_mlp_1_power': 3, 'edge_mlp_2_power': 2, 'node_mlp_1_power': 2}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'optimizer': CategoricalDistribution(choices=('adam', 'sgd')), 'learning_rate': FloatDistribution(high=0.003, log=True, low=0.0003, step=None), 'momentum': FloatDistribution(high=0.999, log=False, low=0.0, step=None), 'n_blocks': IntDistribution(high=3, log=False, low=1, step=1), 'dropout_rate': FloatDistribution(high=0.2, log=False, low=0.0, step=None), 'activation': CategoricalDistribution(choices=('relu', 'elu', 'leaky_relu')), 'edge_mlp_1_power': IntDistribution(high=3, log=False, low=1, step=1), 'edge_mlp_2_power': IntDistribution(high=3, log=False, low=1, step=1), 'node_mlp_1_power': IntDistribution(high=6, log=False, low=1, step=1)}, trial_id=1, value=None),\n",
       " FrozenTrial(number=1, state=1, values=[330.6016845703125], datetime_start=datetime.datetime(2024, 2, 12, 19, 45, 53, 573985), datetime_complete=datetime.datetime(2024, 2, 12, 19, 45, 55, 19819), params={'optimizer': 'adam', 'learning_rate': 0.0004631000672680302, 'n_blocks': 1, 'dropout_rate': 0.0381523668629391, 'activation': 'leaky_relu', 'edge_mlp_1_power': 2, 'edge_mlp_2_power': 2, 'node_mlp_1_power': 5}, user_attrs={}, system_attrs={}, intermediate_values={0: 852.4498291015625, 1: 570.6085815429688, 2: 409.4997863769531, 3: 330.6016845703125}, distributions={'optimizer': CategoricalDistribution(choices=('adam', 'sgd')), 'learning_rate': FloatDistribution(high=0.003, log=True, low=0.0003, step=None), 'n_blocks': IntDistribution(high=3, log=False, low=1, step=1), 'dropout_rate': FloatDistribution(high=0.2, log=False, low=0.0, step=None), 'activation': CategoricalDistribution(choices=('relu', 'elu', 'leaky_relu')), 'edge_mlp_1_power': IntDistribution(high=3, log=False, low=1, step=1), 'edge_mlp_2_power': IntDistribution(high=3, log=False, low=1, step=1), 'node_mlp_1_power': IntDistribution(high=6, log=False, low=1, step=1)}, trial_id=2, value=None),\n",
       " FrozenTrial(number=2, state=1, values=[2154.8974609375], datetime_start=datetime.datetime(2024, 2, 12, 19, 45, 55, 30040), datetime_complete=datetime.datetime(2024, 2, 12, 19, 45, 57, 248435), params={'optimizer': 'adam', 'learning_rate': 0.000904660094615911, 'n_blocks': 2, 'dropout_rate': 0.16681692177520147, 'activation': 'relu', 'edge_mlp_1_power': 3, 'edge_mlp_2_power': 3, 'node_mlp_1_power': 5}, user_attrs={}, system_attrs={}, intermediate_values={0: 11869.03125, 1: 9392.248046875, 2: 3596.195556640625, 3: 2154.8974609375}, distributions={'optimizer': CategoricalDistribution(choices=('adam', 'sgd')), 'learning_rate': FloatDistribution(high=0.003, log=True, low=0.0003, step=None), 'n_blocks': IntDistribution(high=3, log=False, low=1, step=1), 'dropout_rate': FloatDistribution(high=0.2, log=False, low=0.0, step=None), 'activation': CategoricalDistribution(choices=('relu', 'elu', 'leaky_relu')), 'edge_mlp_1_power': IntDistribution(high=3, log=False, low=1, step=1), 'edge_mlp_2_power': IntDistribution(high=3, log=False, low=1, step=1), 'node_mlp_1_power': IntDistribution(high=6, log=False, low=1, step=1)}, trial_id=3, value=None),\n",
       " FrozenTrial(number=3, state=1, values=[8.69314956665039], datetime_start=datetime.datetime(2024, 2, 12, 19, 45, 57, 256343), datetime_complete=datetime.datetime(2024, 2, 12, 19, 45, 59, 510631), params={'optimizer': 'adam', 'learning_rate': 0.0023802358939410116, 'n_blocks': 2, 'dropout_rate': 0.18770788967261381, 'activation': 'leaky_relu', 'edge_mlp_1_power': 1, 'edge_mlp_2_power': 1, 'node_mlp_1_power': 3}, user_attrs={}, system_attrs={}, intermediate_values={0: 162.06271362304688, 1: 8.573760986328125, 2: 8.532217025756836, 3: 8.69314956665039}, distributions={'optimizer': CategoricalDistribution(choices=('adam', 'sgd')), 'learning_rate': FloatDistribution(high=0.003, log=True, low=0.0003, step=None), 'n_blocks': IntDistribution(high=3, log=False, low=1, step=1), 'dropout_rate': FloatDistribution(high=0.2, log=False, low=0.0, step=None), 'activation': CategoricalDistribution(choices=('relu', 'elu', 'leaky_relu')), 'edge_mlp_1_power': IntDistribution(high=3, log=False, low=1, step=1), 'edge_mlp_2_power': IntDistribution(high=3, log=False, low=1, step=1), 'node_mlp_1_power': IntDistribution(high=6, log=False, low=1, step=1)}, trial_id=4, value=None),\n",
       " FrozenTrial(number=4, state=1, values=[36.22504425048828], datetime_start=datetime.datetime(2024, 2, 12, 19, 45, 59, 518357), datetime_complete=datetime.datetime(2024, 2, 12, 19, 46, 2, 641454), params={'optimizer': 'adam', 'learning_rate': 0.0029065367470494418, 'n_blocks': 3, 'dropout_rate': 0.13386631775638555, 'activation': 'leaky_relu', 'edge_mlp_1_power': 2, 'edge_mlp_2_power': 1, 'node_mlp_1_power': 5}, user_attrs={}, system_attrs={}, intermediate_values={0: 202.2373809814453, 1: 229.86270141601562, 2: 43.494110107421875, 3: 36.22504425048828}, distributions={'optimizer': CategoricalDistribution(choices=('adam', 'sgd')), 'learning_rate': FloatDistribution(high=0.003, log=True, low=0.0003, step=None), 'n_blocks': IntDistribution(high=3, log=False, low=1, step=1), 'dropout_rate': FloatDistribution(high=0.2, log=False, low=0.0, step=None), 'activation': CategoricalDistribution(choices=('relu', 'elu', 'leaky_relu')), 'edge_mlp_1_power': IntDistribution(high=3, log=False, low=1, step=1), 'edge_mlp_2_power': IntDistribution(high=3, log=False, low=1, step=1), 'node_mlp_1_power': IntDistribution(high=6, log=False, low=1, step=1)}, trial_id=5, value=None)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.hyperparam_tuning import get_best_trial_config, get_best_trial_workdir\n",
    "from utils.jraph_vis import plot_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/miamirabelli/Desktop/GNN Research/lorenzGNN/sample.ipynb Cell 61\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/miamirabelli/Desktop/GNN%20Research/lorenzGNN/sample.ipynb#Y130sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m plot_predictions(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/miamirabelli/Desktop/GNN%20Research/lorenzGNN/sample.ipynb#Y130sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     config\u001b[39m=\u001b[39;49mget_best_trial_config(study\u001b[39m=\u001b[39;49mstudy),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/miamirabelli/Desktop/GNN%20Research/lorenzGNN/sample.ipynb#Y130sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     workdir\u001b[39m=\u001b[39;49mget_best_trial_workdir(study\u001b[39m=\u001b[39;49mstudy), \u001b[39m# for loading checkpoints \u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/miamirabelli/Desktop/GNN%20Research/lorenzGNN/sample.ipynb#Y130sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     plot_ith_rollout_step\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, \u001b[39m# 0 indexed # for this study, we have a 4-step rollout \u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/miamirabelli/Desktop/GNN%20Research/lorenzGNN/sample.ipynb#Y130sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m# dataset,\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/miamirabelli/Desktop/GNN%20Research/lorenzGNN/sample.ipynb#Y130sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m# preds,\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/miamirabelli/Desktop/GNN%20Research/lorenzGNN/sample.ipynb#Y130sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m# timestep_duration,\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/miamirabelli/Desktop/GNN%20Research/lorenzGNN/sample.ipynb#Y130sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m# n_rollout_steps,\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/miamirabelli/Desktop/GNN%20Research/lorenzGNN/sample.ipynb#Y130sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m#  total_steps,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/miamirabelli/Desktop/GNN%20Research/lorenzGNN/sample.ipynb#Y130sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     node\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, \u001b[39m# 0-indexed \u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/miamirabelli/Desktop/GNN%20Research/lorenzGNN/sample.ipynb#Y130sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     plot_mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mval\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m# i.e. \"train\"/\"val\"/\"test\"\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/miamirabelli/Desktop/GNN%20Research/lorenzGNN/sample.ipynb#Y130sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     datasets\u001b[39m=\u001b[39;49mdatasets,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/miamirabelli/Desktop/GNN%20Research/lorenzGNN/sample.ipynb#Y130sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m# plot_days=60,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/miamirabelli/Desktop/GNN%20Research/lorenzGNN/sample.ipynb#Y130sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/GNN Research/lorenzGNN/utils/jraph_vis.py:145\u001b[0m, in \u001b[0;36mplot_predictions\u001b[0;34m(config, workdir, plot_ith_rollout_step, node, plot_mode, datasets, plot_days, title)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[39massert\u001b[39;00m plot_mode \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mval\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    144\u001b[0m checkpoint_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(workdir, \u001b[39m'\u001b[39m\u001b[39mcheckpoints\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 145\u001b[0m \u001b[39massert\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(checkpoint_dir)\n\u001b[1;32m    147\u001b[0m \u001b[39m# samples must be overlapping and consecutive for this plot to really be interpretable the way it is meant \u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[39massert\u001b[39;00m (\n\u001b[1;32m    149\u001b[0m     config\u001b[39m.\u001b[39minput_steps \u001b[39m+\u001b[39m config\u001b[39m.\u001b[39moutput_delay \u001b[39m+\u001b[39m config\u001b[39m.\u001b[39moutput_steps \u001b[39m+\u001b[39m config\u001b[39m.\u001b[39msample_buffer \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    150\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "plot_predictions(\n",
    "    config=get_best_trial_config(study=study),\n",
    "    workdir=get_best_trial_workdir(study=study), # for loading checkpoints \n",
    "    plot_ith_rollout_step=0, # 0 indexed # for this study, we have a 4-step rollout \n",
    "    # dataset,\n",
    "    # preds,\n",
    "    # timestep_duration,\n",
    "    # n_rollout_steps,\n",
    "    #  total_steps,\n",
    "    node=0, # 0-indexed \n",
    "    plot_mode=\"val\", # i.e. \"train\"/\"val\"/\"test\"\n",
    "    datasets=datasets,\n",
    "    # plot_days=60,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
