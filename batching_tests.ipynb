{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will be checking if my batching implementation is up to snuff. Essentially, I hope to see that I have fewer batches than windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# ipython extension to autoreload imported modules so that any changes will be up to date before running code in this nb\n",
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.jraph_data import get_lorenz_graph_tuples, print_graph_fts\n",
    "from utils.lorenz import load_lorenz96_2coupled\n",
    "\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml_collections\n",
    "\n",
    "config = ml_collections.ConfigDict()\n",
    "\n",
    "# Data params. \n",
    "config.n_samples=20\n",
    "config.input_steps=1\n",
    "config.output_delay=0 # predict 0 hours into the future\n",
    "config.output_steps=4\n",
    "config.timestep_duration=3\n",
    "config.sample_buffer=-1 * (config.input_steps + config.output_delay + config.output_steps - 1) # negative buffer so that our sample input are continuous (i.e. the first sample would overlap a bit with consecutive samples) \n",
    "config.time_resolution=120\n",
    "config.init_buffer_samples=0\n",
    "config.train_pct=0.7\n",
    "config.val_pct=0.2\n",
    "config.test_pct=0.1\n",
    "config.K=6\n",
    "config.F=8\n",
    "config.c=10\n",
    "config.b=10\n",
    "config.h=1\n",
    "config.seed=42\n",
    "config.normalize=True\n",
    "config.fully_connected_edges=False\n",
    "\n",
    "# Optimizer.\n",
    "config.optimizer = 'adam'\n",
    "config.learning_rate = 1e-3\n",
    "\n",
    "# Training hyperparameters.\n",
    "config.batch_size = 2\n",
    "config.epochs = 150\n",
    "config.log_every_epochs = 5\n",
    "config.eval_every_epochs = 5\n",
    "config.checkpoint_every_epochs = 10\n",
    "config.max_checkpts_to_keep = 2 # None means keep all checkpoints\n",
    "\n",
    "# GNN hyperparameters.\n",
    "config.model = 'MLPGraphNetwork'\n",
    "config.n_blocks = 1\n",
    "config.activation = 'relu'\n",
    "config.dropout_rate = 0.1\n",
    "config.skip_connections = False # This was throwing a broadcast error in add_graphs_tuples_nodes when this was set to True\n",
    "config.layer_norm = False # TODO perhaps we want to turn on later\n",
    "config.edge_features = (4, 8) # the last feature size will be the number of features that the graph predicts\n",
    "config.node_features = (32, 2)\n",
    "config.global_features = None\n",
    "config.share_params = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.jraph_data import get_lorenz_graph_tuples, print_graph_fts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate desired dataset with train/val split and subsampled windows\n",
    "graph_tuple_dict, batched_graph_tuple_dict = get_lorenz_graph_tuples(\n",
    "    n_samples=config.n_samples,\n",
    "    input_steps=config.input_steps,\n",
    "    output_delay=config.output_delay,\n",
    "    output_steps=config.output_steps,\n",
    "    timestep_duration=config.timestep_duration,\n",
    "    sample_buffer=config.sample_buffer,\n",
    "    time_resolution=config.time_resolution,\n",
    "    init_buffer_samples=config.init_buffer_samples,\n",
    "    train_pct=config.train_pct,\n",
    "    val_pct=config.val_pct,\n",
    "    test_pct=config.test_pct,\n",
    "    K=config.K,\n",
    "    F=config.F,\n",
    "    c=config.c,\n",
    "    b=config.b,\n",
    "    h=config.h,\n",
    "    seed=config.seed,\n",
    "    normalize=config.normalize,\n",
    "    fully_connected_edges=config.fully_connected_edges,\n",
    "    batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph_tuple_dict type: <class 'dict'>\n",
      "graph_tuple_dict keys: dict_keys(['train', 'val', 'test'])\n",
      "graph_tuple_dict value type: <class 'dict'>\n",
      "train dataset keys: dict_keys(['inputs', 'targets'])\n",
      "train dataset value type: <class 'list'>\n",
      "size of train inputs: 14\n",
      "size of train targets: 14\n",
      "size of val inputs: 4\n",
      "size of val targets: 4\n",
      "size of test inputs: 2\n",
      "size of test targets: 2\n",
      "train inputs window type: <class 'list'>\n",
      "train input window size (i.e. input steps per window): 1\n",
      "element type in window: <class 'jraph._src.graph.GraphsTuple'>\n"
     ]
    }
   ],
   "source": [
    "train_dataset = graph_tuple_dict['train']\n",
    "val_dataset = graph_tuple_dict['val']\n",
    "test_dataset = graph_tuple_dict['test']\n",
    "\n",
    "train_inputs = train_dataset['inputs']\n",
    "train_targets = train_dataset['targets']\n",
    "val_inputs = val_dataset['inputs']\n",
    "val_targets = val_dataset['targets']\n",
    "test_inputs = test_dataset['inputs']\n",
    "test_targets = test_dataset['targets']\n",
    "\n",
    "sample_input_window = train_inputs[0]\n",
    "sample_target_window = train_targets[0]\n",
    "sample_graph = sample_input_window[0]\n",
    "\n",
    "print(\"graph_tuple_dict type:\", type(graph_tuple_dict))\n",
    "print(\"graph_tuple_dict keys:\", graph_tuple_dict.keys())\n",
    "print(\"graph_tuple_dict value type:\", type(train_dataset))\n",
    "print(\"train dataset keys:\", train_dataset.keys())\n",
    "print(\"train dataset value type:\", type(train_inputs))\n",
    "\n",
    "print(\"size of train inputs:\", len(train_inputs))\n",
    "print(\"size of train targets:\", len(train_targets))\n",
    "print(\"size of val inputs:\", len(val_inputs))\n",
    "print(\"size of val targets:\", len(val_targets))\n",
    "print(\"size of test inputs:\", len(test_inputs))\n",
    "print(\"size of test targets:\", len(test_targets))\n",
    "\n",
    "print(\"train inputs window type:\", type(sample_input_window))\n",
    "print(\"train input window size (i.e. input steps per window):\", len(sample_input_window))\n",
    "print(\"element type in window:\", type(sample_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph_tuple_dict type: <class 'dict'>\n",
      "graph_tuple_dict keys: dict_keys(['train', 'val', 'test'])\n",
      "graph_tuple_dict value type: <class 'dict'>\n",
      "train dataset keys: dict_keys(['inputs', 'targets'])\n",
      "train dataset value type: <class 'list'>\n",
      "size of train inputs: 7\n",
      "size of train targets: 7\n",
      "size of val inputs: 2\n",
      "size of val targets: 2\n",
      "size of test inputs: 1\n",
      "size of test targets: 1\n",
      "train inputs window type: <class 'list'>\n",
      "train input window size (i.e. input steps per window): 2\n",
      "element type in window: <class 'jraph._src.graph.GraphsTuple'>\n"
     ]
    }
   ],
   "source": [
    "train_dataset = batched_graph_tuple_dict['train']\n",
    "val_dataset = batched_graph_tuple_dict['val']\n",
    "test_dataset = batched_graph_tuple_dict['test']\n",
    "\n",
    "train_inputs = train_dataset['inputs']\n",
    "train_targets = train_dataset['targets']\n",
    "val_inputs = val_dataset['inputs']\n",
    "val_targets = val_dataset['targets']\n",
    "test_inputs = test_dataset['inputs']\n",
    "test_targets = test_dataset['targets']\n",
    "\n",
    "sample_input_window = train_inputs[0]\n",
    "sample_target_window = train_targets[0]\n",
    "batched_sample_graph = sample_input_window[0]\n",
    "\n",
    "print(\"graph_tuple_dict type:\", type(batched_graph_tuple_dict))\n",
    "print(\"graph_tuple_dict keys:\", batched_graph_tuple_dict.keys())\n",
    "print(\"graph_tuple_dict value type:\", type(train_dataset))\n",
    "print(\"train dataset keys:\", train_dataset.keys())\n",
    "print(\"train dataset value type:\", type(train_inputs))\n",
    "\n",
    "print(\"size of train inputs:\", len(train_inputs))\n",
    "print(\"size of train targets:\", len(train_targets))\n",
    "print(\"size of val inputs:\", len(val_inputs))\n",
    "print(\"size of val targets:\", len(val_targets))\n",
    "print(\"size of test inputs:\", len(test_inputs))\n",
    "print(\"size of test targets:\", len(test_targets))\n",
    "\n",
    "print(\"train inputs window type:\", type(sample_input_window))\n",
    "print(\"train input window size (i.e. input steps per window):\", len(sample_input_window))\n",
    "print(\"element type in window:\", type(batched_sample_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GraphsTuple(nodes=array([[ 1.1636245 ,  1.0790482 ],\n",
      "       [-1.293495  , -0.35579923],\n",
      "       [ 0.37819758,  0.18474741],\n",
      "       [ 0.37264496, -1.640342  ],\n",
      "       [ 0.20188326, -1.047298  ],\n",
      "       [ 1.1561959 ,  3.074735  ]], dtype=float32), edges=Array([[ 0.],\n",
      "       [ 1.],\n",
      "       [ 2.],\n",
      "       [-1.],\n",
      "       [-2.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 2.],\n",
      "       [-1.],\n",
      "       [-2.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 2.],\n",
      "       [-1.],\n",
      "       [-2.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 2.],\n",
      "       [-1.],\n",
      "       [-2.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 2.],\n",
      "       [-1.],\n",
      "       [-2.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 2.],\n",
      "       [-1.],\n",
      "       [-2.]], dtype=float32), receivers=Array([0, 1, 2, 5, 4, 1, 2, 3, 0, 5, 2, 3, 4, 1, 0, 3, 4, 5, 2, 1, 4, 5,\n",
      "       0, 3, 2, 5, 0, 1, 4, 3], dtype=int32), senders=Array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4,\n",
      "       4, 4, 4, 5, 5, 5, 5, 5], dtype=int32), globals=Array([[1.]], dtype=float32), n_node=Array([6], dtype=int32), n_edge=Array([30], dtype=int32))]\n"
     ]
    }
   ],
   "source": [
    "print(graph_tuple_dict['val']['inputs'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GraphsTuple(nodes=Array([[ 1.1636245 ,  1.0790482 ],\n",
      "       [-1.293495  , -0.35579923],\n",
      "       [ 0.37819758,  0.18474741],\n",
      "       [ 0.37264496, -1.640342  ],\n",
      "       [ 0.20188326, -1.047298  ],\n",
      "       [ 1.1561959 ,  3.074735  ]], dtype=float32), edges=Array([[ 0.],\n",
      "       [ 1.],\n",
      "       [ 2.],\n",
      "       [-1.],\n",
      "       [-2.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 2.],\n",
      "       [-1.],\n",
      "       [-2.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 2.],\n",
      "       [-1.],\n",
      "       [-2.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 2.],\n",
      "       [-1.],\n",
      "       [-2.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 2.],\n",
      "       [-1.],\n",
      "       [-2.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 2.],\n",
      "       [-1.],\n",
      "       [-2.]], dtype=float32), receivers=Array([0, 1, 2, 5, 4, 1, 2, 3, 0, 5, 2, 3, 4, 1, 0, 3, 4, 5, 2, 1, 4, 5,\n",
      "       0, 3, 2, 5, 0, 1, 4, 3], dtype=int32), senders=Array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4,\n",
      "       4, 4, 4, 5, 5, 5, 5, 5], dtype=int32), globals=Array([[1.]], dtype=float32), n_node=Array([6], dtype=int32), n_edge=Array([30], dtype=int32)), GraphsTuple(nodes=Array([[ 1.0018804 ,  1.8181608 ],\n",
      "       [-1.2903361 ,  0.27553296],\n",
      "       [ 0.43631706,  0.3780051 ],\n",
      "       [ 0.5541917 , -0.17729115],\n",
      "       [ 0.3262986 , -1.8358552 ],\n",
      "       [ 1.1800684 ,  1.5343047 ]], dtype=float32), edges=Array([[ 0.],\n",
      "       [ 1.],\n",
      "       [ 2.],\n",
      "       [-1.],\n",
      "       [-2.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 2.],\n",
      "       [-1.],\n",
      "       [-2.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 2.],\n",
      "       [-1.],\n",
      "       [-2.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 2.],\n",
      "       [-1.],\n",
      "       [-2.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 2.],\n",
      "       [-1.],\n",
      "       [-2.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 2.],\n",
      "       [-1.],\n",
      "       [-2.]], dtype=float32), receivers=Array([0, 1, 2, 5, 4, 1, 2, 3, 0, 5, 2, 3, 4, 1, 0, 3, 4, 5, 2, 1, 4, 5,\n",
      "       0, 3, 2, 5, 0, 1, 4, 3], dtype=int32), senders=Array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4,\n",
      "       4, 4, 4, 5, 5, 5, 5, 5], dtype=int32), globals=Array([[1.]], dtype=float32), n_node=Array([6], dtype=int32), n_edge=Array([30], dtype=int32))]\n"
     ]
    }
   ],
   "source": [
    "print(batched_graph_tuple_dict['val']['inputs'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok so we have the batching data structure mostly working. lets see if this runs! at all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.jraph_training import train_and_evaluate_with_data\n",
    "from utils.jraph_vis import plot_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Hyperparameters: {'F': 8, 'K': 6, 'activation': 'relu', 'b': 10, 'batch_size': 2, 'c': 10, 'checkpoint_every_epochs': 10, 'dropout_rate': 0.1, 'edge_features': (4, 8), 'epochs': 150, 'eval_every_epochs': 5, 'fully_connected_edges': False, 'global_features': None, 'h': 1, 'init_buffer_samples': 0, 'input_steps': 1, 'layer_norm': False, 'learning_rate': 0.001, 'log_every_epochs': 5, 'max_checkpts_to_keep': 2, 'model': 'MLPGraphNetwork', 'n_blocks': 1, 'n_samples': 20, 'node_features': (32, 2), 'normalize': True, 'optimizer': 'adam', 'output_delay': 0, 'output_steps': 4, 'sample_buffer': -4, 'seed': 42, 'share_params': False, 'skip_connections': False, 'test_pct': 0.1, 'time_resolution': 120, 'timestep_duration': 3, 'train_pct': 0.7, 'val_pct': 0.2}\n",
      "INFO:absl:Initializing network.\n",
      "INFO:absl:\n",
      "+----------------------------------------+----------+------+----------+-------+\n",
      "| Name                                   | Shape    | Size | Mean     | Std   |\n",
      "+----------------------------------------+----------+------+----------+-------+\n",
      "| params/MLPBlock_0/MLP_0/Dense_0/bias   | (4,)     | 4    | 0.0      | 0.0   |\n",
      "| params/MLPBlock_0/MLP_0/Dense_0/kernel | (6, 4)   | 24   | -0.0819  | 0.36  |\n",
      "| params/MLPBlock_0/MLP_0/Dense_1/bias   | (8,)     | 8    | 0.0      | 0.0   |\n",
      "| params/MLPBlock_0/MLP_0/Dense_1/kernel | (4, 8)   | 32   | -0.0639  | 0.439 |\n",
      "| params/MLPBlock_0/MLP_1/Dense_0/bias   | (32,)    | 32   | 0.0      | 0.0   |\n",
      "| params/MLPBlock_0/MLP_1/Dense_0/kernel | (19, 32) | 608  | -0.00843 | 0.219 |\n",
      "| params/MLPBlock_0/MLP_1/Dense_1/bias   | (2,)     | 2    | 0.0      | 0.0   |\n",
      "| params/MLPBlock_0/MLP_1/Dense_1/kernel | (32, 2)  | 64   | -0.00627 | 0.195 |\n",
      "+----------------------------------------+----------+------+----------+-------+\n",
      "Total: 774\n",
      "INFO:absl:Checkpoint.restore_or_initialize() ...\n",
      "INFO:absl:No checkpoint specified. Restore the latest checkpoint.\n",
      "INFO:absl:Restoring checkpoint: tests/outputs/batch_test/checkpoints/ckpt-1\n",
      "INFO:absl:Restored save_counter=1 restored_checkpoint=tests/outputs/batch_test/checkpoints/ckpt-1\n",
      "INFO:absl:Checkpoint.restore_or_initialize() finished after 0.00s.\n",
      "INFO:absl:Starting training.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "vmap in_axes specification must be a tree prefix of the corresponding value, got specification ((1, 1, 1, 1, None, None, None), (1, 1, 1, 1, None, None, None)) for value tree PyTreeDef(([CustomNode(namedtuple[GraphsTuple], [*, *, *, *, *, *, *]), CustomNode(namedtuple[GraphsTuple], [*, *, *, *, *, *, *])], [CustomNode(namedtuple[GraphsTuple], [*, *, *, *, *, *, *]), CustomNode(namedtuple[GraphsTuple], [*, *, *, *, *, *, *])])).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/miamirabelli/Desktop/GNN Research/lorenzGNN/batching_tests.ipynb Cell 14\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/miamirabelli/Desktop/GNN%20Research/lorenzGNN/batching_tests.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m workdir\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtests/outputs/batch_test\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/miamirabelli/Desktop/GNN%20Research/lorenzGNN/batching_tests.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m trained_state, train_metrics, eval_metrics_dict \u001b[39m=\u001b[39m train_and_evaluate_with_data(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/miamirabelli/Desktop/GNN%20Research/lorenzGNN/batching_tests.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     config\u001b[39m=\u001b[39;49mconfig, workdir\u001b[39m=\u001b[39;49mworkdir, datasets\u001b[39m=\u001b[39;49mbatched_graph_tuple_dict)\n",
      "File \u001b[0;32m~/Desktop/GNN Research/lorenzGNN/utils/jraph_training.py:630\u001b[0m, in \u001b[0;36mtrain_and_evaluate_with_data\u001b[0;34m(config, workdir, datasets, trial)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39m# Perform one step of training.\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[39mwith\u001b[39;00m jax\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mStepTraceAnnotation(\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m, step_num\u001b[39m=\u001b[39mstep):\n\u001b[1;32m    629\u001b[0m     \u001b[39m# graphs = jax.tree_util.tree_map(np.asarray, next(train_iter))\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m     state, metrics_update, _ \u001b[39m=\u001b[39m train_step(\n\u001b[1;32m    631\u001b[0m         state\u001b[39m=\u001b[39;49mstate, \n\u001b[1;32m    632\u001b[0m         n_rollout_steps\u001b[39m=\u001b[39;49mn_rollout_steps, \n\u001b[1;32m    633\u001b[0m         input_batch_graphs\u001b[39m=\u001b[39;49minput_batch_graphs, \n\u001b[1;32m    634\u001b[0m         target_batch_graphs\u001b[39m=\u001b[39;49mtarget_batch_graphs,\n\u001b[1;32m    635\u001b[0m         rngs\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mdropout\u001b[39;49m\u001b[39m'\u001b[39;49m: dropout_rng},\n\u001b[1;32m    636\u001b[0m     )\n\u001b[1;32m    637\u001b[0m     \u001b[39mif\u001b[39;00m jnp\u001b[39m.\u001b[39misnan(metrics_update\u001b[39m.\u001b[39mloss\u001b[39m.\u001b[39mtotal):\n\u001b[1;32m    638\u001b[0m         \u001b[39m# TODO is it ok to raise the prune even if the pruner doesn't say should prune? \u001b[39;00m\n\u001b[1;32m    639\u001b[0m         logging\u001b[39m.\u001b[39mwarning(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mloss is nan for step \u001b[39m\u001b[39m{\u001b[39;00mstep\u001b[39m}\u001b[39;00m\u001b[39m (in epoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m)\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/GNN Research/lorenzGNN/utils/jraph_training.py:380\u001b[0m, in \u001b[0;36mtrain_step_fn\u001b[0;34m(state, n_rollout_steps, input_batch_graphs, target_batch_graphs, rngs)\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[39mreturn\u001b[39;00m total_loss, (loss_metrics, batch_pred_nodes)\n\u001b[1;32m    379\u001b[0m grad_fn \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mvalue_and_grad(loss_fn, has_aux\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 380\u001b[0m (loss, (loss_metrics, pred_nodes)), grads \u001b[39m=\u001b[39m grad_fn(state\u001b[39m.\u001b[39;49mparams, input_batch_graphs, target_batch_graphs)\n\u001b[1;32m    381\u001b[0m state \u001b[39m=\u001b[39m state\u001b[39m.\u001b[39mapply_gradients(grads\u001b[39m=\u001b[39mgrads) \u001b[39m# update params in the state \u001b[39;00m\n\u001b[1;32m    383\u001b[0m metrics_update \u001b[39m=\u001b[39m TrainMetrics\u001b[39m.\u001b[39msingle_from_model_output(loss\u001b[39m=\u001b[39mloss,\n\u001b[1;32m    384\u001b[0m                                                        x1_loss\u001b[39m=\u001b[39mloss_metrics[\u001b[39m'\u001b[39m\u001b[39mx1_loss\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m    385\u001b[0m                                                        x2_loss\u001b[39m=\u001b[39mloss_metrics[\u001b[39m'\u001b[39m\u001b[39mx2_loss\u001b[39m\u001b[39m'\u001b[39m])\n",
      "    \u001b[0;31m[... skipping hidden 8 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/GNN Research/lorenzGNN/utils/jraph_training.py:369\u001b[0m, in \u001b[0;36mtrain_step_fn.<locals>.loss_fn\u001b[0;34m(params, input_batch_graphs, target_batch_graphs)\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[39mreturn\u001b[39;00m total_loss, x1_loss, x2_loss, pred_nodes\n\u001b[1;32m    368\u001b[0m \u001b[39m# applies the loss fn to every window in the batches\u001b[39;00m\n\u001b[0;32m--> 369\u001b[0m batch_losses, batch_x1_losses, batch_x2_losses, batch_pred_nodes \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39;49mvmap(\n\u001b[1;32m    370\u001b[0m     \u001b[39mlambda\u001b[39;49;00m x, y: compute_loss(x, y), in_axes\u001b[39m=\u001b[39;49m[(\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m), (\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)])(input_batch_graphs, target_batch_graphs)\n\u001b[1;32m    372\u001b[0m total_loss \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39mmean(batch_losses)\n\u001b[1;32m    373\u001b[0m total_x1_loss \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39mmean(batch_x1_losses)\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/GNN Research/lorenzGNN/venv/lib/python3.11/site-packages/jax/_src/api_util.py:433\u001b[0m, in \u001b[0;36mflatten_axes\u001b[0;34m(name, treedef, axis_tree, kws, tupled_args)\u001b[0m\n\u001b[1;32m    429\u001b[0m       \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    430\u001b[0m         hint \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m In particular, you\u001b[39m\u001b[39m'\u001b[39m\u001b[39mre passing in a single argument which \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    431\u001b[0m                  \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmeans that \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m might need to be wrapped in \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    432\u001b[0m                  \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39ma singleton tuple.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 433\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m specification must be a tree prefix of the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    434\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcorresponding value, got specification \u001b[39m\u001b[39m{\u001b[39;00maxis_tree\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    435\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfor value tree \u001b[39m\u001b[39m{\u001b[39;00mtreedef\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhint\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    436\u001b[0m axes \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m a \u001b[39mis\u001b[39;00m proxy \u001b[39melse\u001b[39;00m a \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m axes]\n\u001b[1;32m    437\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(axes) \u001b[39m==\u001b[39m treedef\u001b[39m.\u001b[39mnum_leaves\n",
      "\u001b[0;31mValueError\u001b[0m: vmap in_axes specification must be a tree prefix of the corresponding value, got specification ((1, 1, 1, 1, None, None, None), (1, 1, 1, 1, None, None, None)) for value tree PyTreeDef(([CustomNode(namedtuple[GraphsTuple], [*, *, *, *, *, *, *]), CustomNode(namedtuple[GraphsTuple], [*, *, *, *, *, *, *])], [CustomNode(namedtuple[GraphsTuple], [*, *, *, *, *, *, *]), CustomNode(namedtuple[GraphsTuple], [*, *, *, *, *, *, *])]))."
     ]
    }
   ],
   "source": [
    "workdir=\"tests/outputs/batch_test\"\n",
    "\n",
    "trained_state, train_metrics, eval_metrics_dict = train_and_evaluate_with_data(\n",
    "    config=config, workdir=workdir, datasets=batched_graph_tuple_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(\n",
    "    config=config,\n",
    "    workdir=workdir, # for loading checkpoints \n",
    "    plot_ith_rollout_step=0, # 0 indexed # for this study, we have a 4-step rollout \n",
    "    # dataset,\n",
    "    # preds,\n",
    "    # timestep_duration,\n",
    "    # n_rollout_steps,\n",
    "    #  total_steps,\n",
    "    node=0, # 0-indexed \n",
    "    plot_mode=\"val\", # i.e. \"train\"/\"val\"/\"test\"\n",
    "    plot_days=60,\n",
    "    title=\"Val Predictions for node 0, rollout step 0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok so the training isn't working that well\n",
    "we need to see what the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
